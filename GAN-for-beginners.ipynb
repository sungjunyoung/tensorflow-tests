{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/MNIST_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x127dba2e8>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvvEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1111c60f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_image = mnist.train.next_batch(1)[0]\n",
    "print(sample_image.shape)\n",
    "\n",
    "sample_image = sample_image.reshape([28, 28])\n",
    "plt.imshow(sample_image, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(images, reuse=False):\n",
    "    if(reuse):\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "    \n",
    "    # layer 1 (Convolutional and pool lyaers) -> 5 X 5 pixel features\n",
    "    d_w1 = tf.get_variable('d_w1', [5,5,1,32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b1 = tf.get_variable('d_b1', [32], initializer=tf.constant_initializer(0))\n",
    "    d1 = tf.nn.conv2d(input= images, filter= d_w1, strides=[1,1,1,1], padding='SAME')\n",
    "    d1 = d1 + d_b1\n",
    "    d1 = tf.nn.relu(d1)\n",
    "    d1 = tf.nn.avg_pool(d1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    \n",
    "    # layer 2 (Convolutional and pool layers) -> 5 X 5 pixel features\n",
    "    d_w2 = tf.get_variable('d_w2', [5,5,32,64], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b2 = tf.get_variable('d_b2', [64], initializer=tf.constant_initializer(0))\n",
    "    d2 = tf.nn.conv2d(input=d1, filter=d_w2, strides=[1,1,1,1], padding='SAME')\n",
    "    d2 = d2 + d_b2\n",
    "    d2 = tf.nn.relu(d2)\n",
    "    d2 = tf.nn.avg_pool(d2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    \n",
    "    # layer 3 (First fully connected layer)\n",
    "    d_w3 = tf.get_variable('d_w3', [7*7*64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b3 = tf.get_variable('d_b3', [1024], initializer=tf.constant_initializer(0))\n",
    "    d3 = tf.reshape(d2, [-1, 7*7*64])\n",
    "    d3 = tf.matmul(d3, d_w3)\n",
    "    d3 = d3 + d_b3\n",
    "    d3 = tf.nn.relu(d3)\n",
    "    \n",
    "    # layer 3 (Second fully connected layer)\n",
    "    d_w4 = tf.get_variable('d_w4', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b4 = tf.get_variable('d_b4', [1], initializer=tf.constant_initializer(0))\n",
    "    d4 = tf.matmul(d3, d_w4) + d_b4\n",
    "    \n",
    "    return d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z, batch_size, z_dim):\n",
    "    g_w1 = tf.get_variable('g_w1', [z_dim, 3136],dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b1 = tf.get_variable('g_b1', [3136], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g1 = tf.matmul(z, g_w1) + g_b1\n",
    "    g1 = tf.reshape(g1, [-1, 56, 56, 1])\n",
    "    g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope='bn1')\n",
    "    g1 = tf.nn.relu(g1)\n",
    "    \n",
    "    # Generate 50 features\n",
    "    g_w2 = tf.get_variable('g_w2', [3,3,1,z_dim/2], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b2 = tf.get_variable('g_b2', [z_dim/2], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g2 = tf.nn.conv2d(g1, g_w2, strides=[1,2,2,1], padding='SAME')\n",
    "    g2 = g2 + g_b2\n",
    "    g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5, scope='bn2')\n",
    "    g2 = tf.nn.relu(g2)\n",
    "    g2 = tf.image.resize_images(g2, [56,56])\n",
    "    \n",
    "    # Generate 25 features\n",
    "    g_w3 = tf.get_variable('g_w3', [3,3,z_dim/2, z_dim/4], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b3 = tf.get_variable('g_b3', [z_dim/4], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g3 = tf.nn.conv2d(g2, g_w3, strides=[1,2,2,1], padding='SAME')\n",
    "    g3 = g3 + g_b3\n",
    "    g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5, scope='bn3')\n",
    "    g3 = tf.nn.relu(g3)\n",
    "    g3 = tf.image.resize_images(g3, [56,56])\n",
    "    \n",
    "    # Final convolution with one output channel\n",
    "    g_w4 = tf.get_variable('g_w4', [1,1,z_dim/4, 1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b4 = tf.get_variable('g_b4', [1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g4 = tf.nn.conv2d(g3, g_w4, strides=[1,2,2,1], padding='SAME')\n",
    "    g4 = g4 + g_b4\n",
    "    g4 = tf.sigmoid(g4)\n",
    "    \n",
    "    # Dimensions of g4 : batch_size X 28 X 28 X 1\n",
    "    return g4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_dimensions = 100\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generated_image_output = generator(z_placeholder, 1, z_dimensions)\n",
    "z_batch = np.random.normal(0,1,[1,z_dimensions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB6basQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x127e78978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    generated_image = sess.run(generated_image_output, feed_dict={z_placeholder: z_batch})\n",
    "    generated_image = generated_image.reshape([28,28])\n",
    "    plt.imshow(generated_image, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 50\n",
    "\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions], name='z_placeholder')\n",
    "# feeding input noise to the generator\n",
    "\n",
    "x_placeholder = tf.placeholder(tf.float32, shape=[None, 28,28,1], name='x_placeholder')\n",
    "# feeding input images to the discriminator\n",
    "\n",
    "Gz = generator(z_placeholder, batch_size, z_dimensions)\n",
    "# hold generated images\n",
    "\n",
    "with tf.variable_scope(tf.get_variable_scope(), reuse=False) as scope:\n",
    "    Dx = discriminator(x_placeholder)\n",
    "# hold discriminator prediction probabilities for the **real MNIST** images\n",
    "\n",
    "with tf.variable_scope(tf.get_variable_scope(), reuse=True) as scope:\n",
    "    Dg = discriminator(Gz, reuse=True)\n",
    "# hold discriminator prediction probabilities for **generated** images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dx, labels=tf.ones_like(Dx)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.zeros_like(Dg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.ones_like(Dg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d_w1:0', 'd_b1:0', 'd_w2:0', 'd_b2:0', 'd_w3:0', 'd_b3:0', 'd_w4:0', 'd_b4:0']\n",
      "['g_w1:0', 'g_b1:0', 'g_w2:0', 'g_b2:0', 'g_w3:0', 'g_b3:0', 'g_w4:0', 'g_b4:0']\n"
     ]
    }
   ],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]\n",
    "\n",
    "print([v.name for v in d_vars])\n",
    "print([v.name for v in g_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(tf.get_variable_scope(), reuse=None) as scope:\n",
    "    # Train the discriminator\n",
    "    # fake, real\n",
    "    d_trainer_fake = tf.train.AdamOptimizer(0.0003).minimize(d_loss_fake, var_list=d_vars)\n",
    "    d_trainer_real = tf.train.AdamOptimizer(0.0003).minimize(d_loss_real, var_list=d_vars)\n",
    "\n",
    "    # Train the generator\n",
    "    g_trainer = tf.train.AdamOptimizer(0.0001).minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(tf.get_variable_scope(), reuse=True) as scope:\n",
    "    tf.summary.scalar('Generator_loss', g_loss)\n",
    "    tf.summary.scalar('Discriminator_loss_real', d_loss_real)\n",
    "    tf.summary.scalar('Discriminator_loss_fake', d_loss_fake)\n",
    "\n",
    "    images_for_tensorboard = generator(z_placeholder, batch_size, z_dimensions)\n",
    "    tf.summary.image('Generated_images', images_for_tensorboard, 5)\n",
    "    merged = tf.summary.merge_all()\n",
    "    logdir = \"logs/gan-begineer\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "    writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "with tf.variable_scope(tf.get_variable_scope(), reuse=True) as scope:\n",
    "    # Pre-train discriminator\n",
    "    for i in range(300):\n",
    "        z_batch = np.random.normal(0,1,size=[batch_size, z_dimensions])\n",
    "        real_image_batch = mnist.train.next_batch(batch_size)[0].reshape([batch_size, 28,28,1])\n",
    "        _, _, dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake], {x_placeholder: real_image_batch, z_placeholder: z_batch})\n",
    "\n",
    "        if i%100 == 0:\n",
    "            print(\"dLossReal: \", dLossReal, \"dLossFake: \", dLossFake)\n",
    "\n",
    "    # Train generator and discriminator together\n",
    "    # for i in range(100000):\n",
    "    for i in range(10000):\n",
    "        real_image_batch = mnist.train.next_batch(batch_size)[0].reshape([batch_size, 28,28,1])\n",
    "        z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "\n",
    "        # Train discriminator on both real and fake images\n",
    "        _, _, dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake], {x_placeholder: real_image_batch, z_placeholder: z_batch})\n",
    "\n",
    "        # Train generator\n",
    "        z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "        _ = sess.run(g_trainer, feed_dict={z_placeholder: z_batch})\n",
    "\n",
    "        if i%10 == 0:\n",
    "            # Update TensorBoard with summary statistics\n",
    "            z_batch = np.random.normal(0,1,size=[batch_size, z_dimensions])\n",
    "            summary = sess.run(merged, {z_placeholder: z_batch, x_placeholder: real_image_batch})\n",
    "            writer.add_summary(summary, i)\n",
    "\n",
    "        if i% 100 == 0:\n",
    "            # Every 100 iterations, show a generated image\n",
    "            print('--------------------------------------------------------')\n",
    "            print('Iteration: ', i, 'at', datetime.datetime.now())\n",
    "            z_batch = np.random.normal(0,1,size=[1, z_dimensions])\n",
    "            generated_images = generator(z_placeholder, 1, z_dimensions)\n",
    "            images = sess.run(generated_images, {z_placeholder: z_batch})\n",
    "            plt.imshow(images[0].reshape([28,28]), cmap='Greys')\n",
    "            plt.show()\n",
    "\n",
    "            # Show discriminator's estimate\n",
    "            im = images[0].reshape([1,28,28, 1])\n",
    "            result = discriminator(x_placeholder)\n",
    "            estimate = sess.run(result, {x_placeholder: im})\n",
    "            print(\"Estimate: \", estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
