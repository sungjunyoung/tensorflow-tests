{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 784)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1259e1ef0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n+IGgCD8QFOEHgiL8QFCEHwiK8ANB/Q+Hjhozn0PMPgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1196af2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_image = mnist.train.next_batch(1)[0]\n",
    "print(sample_image.shape)\n",
    "\n",
    "sample_image = sample_image.reshape([28, 28])\n",
    "plt.imshow(sample_image, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(images, reuse=False):\n",
    "    if(reuse):\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "    \n",
    "    # layer 1 (Convolutional and pool lyaers) -> 5 X 5 pixel features\n",
    "    d_w1 = tf.get_variable('d_w1', [5,5,1,32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b1 = tf.get_variable('d_b1', [32], initializer=tf.constant_initializer(0))\n",
    "    d1 = tf.nn.conv2d(input= images, filter= d_w1, strides=[1,1,1,1], padding='SAME')\n",
    "    d1 = d1 + d_b1\n",
    "    d1 = tf.nn.relu(d1)\n",
    "    d1 = tf.nn.avg_pool(d1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    \n",
    "    # layer 2 (Convolutional and pool layers) -> 5 X 5 pixel features\n",
    "    d_w2 = tf.get_variable('d_w2', [5,5,32,64], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b2 = tf.get_variable('d_b2', [64], initializer=tf.constant_initializer(0))\n",
    "    d2 = tf.nn.conv2d(input=d1, filter=d_w2, strides=[1,1,1,1], padding='SAME')\n",
    "    d2 = d2 + d_b2\n",
    "    d2 = tf.nn.relu(d2)\n",
    "    d2 = tf.nn.avg_pool(d2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    \n",
    "    # layer 3 (First fully connected layer)\n",
    "    d_w3 = tf.get_variable('d_w3', [7*7*64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b3 = tf.get_variable('d_b3', [1024], initializer=tf.constant_initializer(0))\n",
    "    d3 = tf.reshape(d2, [-1, 7*7*64])\n",
    "    d3 = tf.matmul(d3, d_w3)\n",
    "    d3 = d3 + d_b3\n",
    "    d3 = tf.nn.relu(d3)\n",
    "    \n",
    "    # layer 3 (Second fully connected layer)\n",
    "    d_w4 = tf.get_variable('d_w4', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b4 = tf.get_variable('d_b4', [1], initializer=tf.constant_initializer(0))\n",
    "    d4 = tf.matmul(d3, d_w4) + d_b4\n",
    "    \n",
    "    return d4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z, batch_size, z_dim):\n",
    "    g_w1 = tf.get_variable('g_w1', [z_dim, 3136],dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b1 = tf.get_variable('g_b1', [3136], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g1 = tf.matmul(z, g_w1) + g_b1\n",
    "    g1 = tf.reshape(g1, [-1, 56, 56, 1])\n",
    "    g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope='bn1')\n",
    "    g1 = tf.nn.relu(g1)\n",
    "    \n",
    "    # Generate 50 features\n",
    "    g_w2 = tf.get_variable('g_w2', [3,3,1,z_dim/2], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b2 = tf.get_variable('g_b2', [z_dim/2], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g2 = tf.nn.conv2d(g1, g_w2, strides=[1,2,2,1], padding='SAME')\n",
    "    g2 = g2 + g_b2\n",
    "    g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5, scope='bn2')\n",
    "    g2 = tf.nn.relu(g2)\n",
    "    g2 = tf.image.resize_images(g2, [56,56])\n",
    "    \n",
    "    # Generate 25 features\n",
    "    g_w3 = tf.get_variable('g_w3', [3,3,z_dim/2, z_dim/4], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b3 = tf.get_variable('g_b3', [z_dim/4], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g3 = tf.nn.conv2d(g2, g_w3, strides=[1,2,2,1], padding='SAME')\n",
    "    g3 = g3 + g_b3\n",
    "    g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5, scope='bn3')\n",
    "    g3 = tf.nn.relu(g3)\n",
    "    g3 = tf.image.resize_images(g3, [56,56])\n",
    "    \n",
    "    # Final convolution with one output channel\n",
    "    g_w4 = tf.get_variable('g_w4', [1,1,z_dim/4, 1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b4 = tf.get_variable('g_b4', [1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g4 = tf.nn.conv2d(g3, g_w4, strides=[1,2,2,1], padding='SAME')\n",
    "    g4 = g4 + g_b4\n",
    "    g4 = tf.sigmoid(g4)\n",
    "    \n",
    "    # Dimensions of g4 : batch_size X 28 X 28 X 1\n",
    "    return g4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_dimensions = 100\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_image_output = generator(z_placeholder, 1, z_dimensions)\n",
    "z_batch = np.random.normal(0,1,[1,z_dimensions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGXFJREFUeJzt3Xlw1dXZB/DvIwIKRGQNWxBBsSog2BQEkWIV1yraqaIw\n1te24nRwlNpFQe3rOK06r1jflroUBcHlLUgVl5aqvKC4ArLJIrJIgQSQVWVfAs/7R67vROV8T0zC\nvdc5388MQ3K/eXIPN3m4yT2/c465O0QkPUfkegAikhtqfpFEqflFEqXmF0mUml8kUWp+kUSp+UUS\npeYXSZSaXyRRR2bzzho3buxt2rQJ5ps2baL1tWrVCmZ79uyhtWVlZTRv27YtzTds2BDMDhw4QGv3\n7dtH8+bNm9N8586dNK9Tp04wi13BeeSR/Ftg//79NN+9ezfNjz766GBWv379an1u9v0AAGYWzI44\ngj/vxb6fjjnmGJpv3ryZ5oWFhcEs9u8+ePBgMNu0aRO2bdsW/odXUK3mN7MLAPwJQC0Aj7v7fezj\n27Rpg3/+85/B/OGHH6b317Bhw2C2dOlSWhv7j+XRRx+l+YgRI4LZtm3baG1paSnNhwwZQvP333+f\n5q1atQpm7BsFAJo2bUrz2NiXLFlC886dOwez7t2709oFCxbQPNaA7D/FunXr0trY99P5559P8yee\neILmv/zlL4PZBx98QGvZfw633XYbra2oyj/2m1ktAA8BuBDAKQCuNrNTqvr5RCS7qvM7f3cAK9x9\npbvvAzAeQP+aGZaIHG7Vaf7WAEoqvF+aue1LzGywmc02s9lbt26txt2JSE067K/2u/sody929+LG\njRsf7rsTkUqqTvOvBVBU4f02mdtE5FugOs3/PoATzex4M6sD4CoAL9XMsETkcLPq7ORjZhcB+G+U\nT/WNcfc/sI9v3bq133DDDcE89mtBgwYNglmjRo1o7aWXXkrzu+++m+YnnHBCMJs1axatveKKK2j+\nxhtv0Dx2DQKb8vrkk09o7a5du2i+aNEiml999dU0Z/+2HTt20NrvfOc7NJ83bx7Nu3XrFszY9SZA\nfIqzWbNmNI9dR1BUVBTMtm/fTmunTJkSzMaOHYv169cf/nl+d58MYHJ1PoeI5IYu7xVJlJpfJFFq\nfpFEqflFEqXmF0mUml8kUdWa5/+m6tWr5x07dgzmZ511Fq1nyzBja7vZnG9l6tmy2l69etHa2F4C\nn376Kc1j874lJSXB7JRT+ELL2PLRK6+8kuajRo2iOZvL/+1vf0trjz/+eJq/8847NGfLjWPXN/Ts\n2ZPmsa/ZqlWraL5w4cJgxpYiA/yak8cffxzr1q2r1Dy/nvlFEqXmF0mUml8kUWp+kUSp+UUSpeYX\nSVRWt+4uKChAnz59gnls59EJEyYEM7ZEEohPacV2gv39738fzJ566ilae+GFF9Kc7WgMAB06dKA5\n2147tvV2bBl1bDotNoX6zDPPBLPp06fTWvb1BoDWrb+2a1yl9e/Pt5ts164dzdevX0/z2HbtTOwx\nZ7sex6asK9Izv0ii1PwiiVLziyRKzS+SKDW/SKLU/CKJUvOLJCqr8/xlZWXYsmVLMH/pJb7tP1va\nunjxYlob22o5dqQyO0G4OnO6ADBp0iSax7bHZkuKly9fTmuLi4tpzpaeAvFrFC655JJgtm7dOlo7\nd+5cmp900kk0Z8uwY9cnPPDAAzSPLZWOHdvet2/fYDZw4EBay44Pf+yxx2htRXrmF0mUml8kUWp+\nkUSp+UUSpeYXSZSaXyRRan6RRFX3iO5VALYDOACgzN3ppPFpp53mr776ajCfOHEivb9ly5YFs5Ej\nR9La+++/n+axufqLL744mN1xxx20NnZE95o1a2j++eefVzmPzRm/+eabNI9tQT1gwACas6PTly5d\nSmtj1yi88MILNGf7Q7BjrgHguuuuo/nu3btpHruGgT2usesXzjvvvGDWr18/zJ8///Af0Z1xtrvz\nK2REJO/ox36RRFW3+R3Aa2Y2x8wG18SARCQ7qvtjf293X2tmzQFMMbOP3P1Lv0Rm/lMYDFRvzzUR\nqVnVeuZ397WZvzcCmATgazsLuvsody929+ImTZpU5+5EpAZVufnNrL6ZFXzxNoDzACyqqYGJyOFV\nnR/7CwFMMrMvPs//uPsrNTIqETnssnpEd9u2bZ0dy3zqqafSerbm/owzzqC17BhrAGjfvj3NZ86c\nGczY9QdAfL46lsfOM5g9e3YwmzFjBq3961//SvMRI0bQ/Cc/+QnN2Xz4gw8+SGv79etH87Vr19Kc\nzaWfdtpptPa9996jeY8ePWgeO2uhZcuWweyjjz6ita1atQpmQ4YMwbJly3REt4iEqflFEqXmF0mU\nml8kUWp+kUSp+UUSldWtu5s0aYJBgwYF84KCAlo/fPjwYHbrrbfS2tjS05///Oc0b9GiRTCLXbYc\nOz78/PPPp/m0adNozrY0j237vXHjRprH/m2xaakxY8YEsy5dutDaUaNG0ZwtbQWAYcOGBbMjjuDP\nezt27KB5bDky+5oA/Mj4zLUzQWxb8G+yjbye+UUSpeYXSZSaXyRRan6RRKn5RRKl5hdJlJpfJFFZ\nXdJbUFDg7EjoCy+8kNazuVV2FDQQ3w558uTJNGfLdgsLC2lt7Djn1atX07xt27Y0Z49LmzZtaO36\n9etpHlvq3LhxY5pv2LAhmMW23h46dCjNY9tjv/7668EsNh9+3HHH0bx27do07979a5tafcmsWbOC\nWf369WltvXr1gtm9996L1atXa0mviISp+UUSpeYXSZSaXyRRan6RRKn5RRKl5hdJVFbX8xcVFeGB\nBx4I5i+//DKtP+aYY4LZxx9/TGtj24Lv2bOH5mzedu/evbSWzcsCwJIlS2gem+fv3LlzMHv33Xdp\nbZ8+fWjerFkzmm/atInm7BoIdnw3wLdLB4C+ffvSnO3BMHbsWFr7ox/9iOZsu3QAWLx4Mc3ZPgmx\nreBPOOGEYBbbC6AiPfOLJErNL5IoNb9IotT8IolS84skSs0vkig1v0iiovP8ZjYGwA8BbHT3Tpnb\nGgOYAKAdgFUArnT3T2Ofq6ysDFu3bg3msbXhbG36tm3baO0rr7xC8+9+97s0379/fzCLzeNPnz6d\n5pdeeinNY+ve2Vx8bL566tSpNN+yZQvNzz33XJqzxz32uP34xz+m+ZNPPknzW265JZjF5unnzp1L\n8127dtH8xRdfpHmtWrWC2cUXX0xrv8lcPlOZZ/6xAC74ym23AZjq7icCmJp5X0S+RaLN7+5vAvjq\n03V/AOMyb48DcFkNj0tEDrOq/s5f6O5f7P/0CQC+j5WI5J1qv+Dn5ZsABjcCNLPBZjbbzGZ//vnn\n1b07EakhVW3+DWbWEgAyfwdPe3T3Ue5e7O7FDRs2rOLdiUhNq2rzvwTg2szb1wLgL22KSN6JNr+Z\n/Q3AewBOMrNSM/sZgPsA9DOz5QDOzbwvIt8i0Xl+dw8d8H7ON72z3bt3Y9GiRcGczX0CwJo1a4LZ\nOefw4TzzzDM0j53Xztaes2sAKuPvf/87zT/77DOas3n+CRMm0NqmTZvSPDYXHzuzYNCgQcEsdob9\nv/71L5qvXLmS5mvXrg1mV18d+rYuN3LkSJrHzoG4+eabac6u3YidX/Hss88Gs9h5BBXpCj+RRKn5\nRRKl5hdJlJpfJFFqfpFEqflFEpXVrbtr1apFjx+OTWl169YtmM2ZM4fWsilGADjzzDNpXlJSEsxK\nS0tp7bHHHkvz2NTO/fffT3O2LTk7Eh0ApkyZQvPY4xLbMr0606CtWrWieWzbcXY8eOxo8o4dO9I8\ndjz40UcfTfNevXoFszvvvJPWsqXORx11FK2tSM/8IolS84skSs0vkig1v0ii1PwiiVLziyRKzS+S\nqKzO8+/fvx8bNwY3/YnOh7MjumPzqrGtuR966CGa33DDDcGsZ8+etDa2rDa2lPm6666j+UcffRTM\nunTpQmvr1q1Lc7YsFgD9egL8+ojY1tzz5s2jOTuqGgDYtnHsehOALx8HgIEDB9J86dKlNGdbzffu\n3ZvWnnzyycFM8/wiEqXmF0mUml8kUWp+kUSp+UUSpeYXSZSaXyRRVn7aVnYUFRX50KFDg/lTTz1F\n64cNGxbMpk2bRmtja+ZjR1Wzrb1btGhBa1u3bk3zHj160Hz06NE0P++884JZ7Djn2FHUscf1pptu\nojm7/9heALFrFJ577jmas+25d+/eTWtXr15Nc7ZXABC//oHN88eub2DXtMybNw/bt2+v1BneeuYX\nSZSaXyRRan6RRKn5RRKl5hdJlJpfJFFqfpFERdfzm9kYAD8EsNHdO2VuuwvA9QA2ZT5suLtPjn2u\ngoICnH322cG8rKyM1k+cODGYsbluIL6+esaMGTR/4okngtmWLVtobfv27Wn+xhtv0Dx25gBb/x3b\n+z72uW+99Vaax44+Z1/T2BHdsesAYvs/sH0UYmvmzzrrLJrPnDmT5mzvCYCfl/C9732P1g4YMCCY\nDR48mNZWVJln/rEALjjE7Q+6e9fMn2jji0h+iTa/u78JYGsWxiIiWVSd3/lvNLMFZjbGzBrV2IhE\nJCuq2vyPAOgAoCuA9QAeCH2gmQ02s9lmNvvTTz+t4t2JSE2rUvO7+wZ3P+DuBwE8BqA7+dhR7l7s\n7sWNGukHBJF8UaXmN7OWFd69HAB/yVhE8k5lpvr+BqAvgKZmVgrgPwH0NbOuABzAKgDhfa1FJC9F\nm9/dD7Uomi8wD9i5cyedHz3xxBNpfWFhYTA7ePAgrY3t8X733XfTnF0HEDur/cgj+cN8ySWX0Dy2\nr3/Dhg2DGZtPBuLn1P/jH/+g+Y4dO2h+xx13BLPYtRefffYZzVetWkXze+65J5iNHDmS1sau3Yhd\nk7Jy5Uqad+3aNZh17NiR1rI9EmL7N1SkK/xEEqXmF0mUml8kUWp+kUSp+UUSpeYXSVRWj+jes2cP\nPU568+bNtJ4tT+3Tpw+tHT9+PM27detG87fffjuY/fSnP6W1zz77LM1jx4fHjh9v2rRpMDv99NNp\n7fHHH0/zZcuW0Zx9PQHg6aefDmbFxcW0NjZFumvXLpqzr1nnzp1p7d69e2kem34tLS2leffuwYti\no9OEO3fuDGZ79uyhtRXpmV8kUWp+kUSp+UUSpeYXSZSaXyRRan6RRKn5RRKV1SO6O3Xq5GzOe/78\n+bS+qKgomL377ru0dvJkvsFwbOtvNiddp04dWhs7Bjt2nPPJJ59M8/r16wez2FHS119/Pc1jx2Cz\nuXQA+MUvfhHMpk+fTmtPOukkmrPrGwB+rPqf//xnWhvz/e9/n+b16tWjOduuPTZXP3z48GDWv39/\nLFy4UEd0i0iYml8kUWp+kUSp+UUSpeYXSZSaXyRRan6RRGV1PX9ZWRldsx9bI822Yr7zzjtpbezY\n4wULFtCcHdkcW89/4MABmg8aNIjm8+bNozmb744dFX3XXXfR/NVXX6X5I488QnO2rj12XcekSZNo\n/oMf/IDmbOvv2GP+hz/8geax60LYduoAwE6vim2n/pe//CWYxa4ZqUjP/CKJUvOLJErNL5IoNb9I\notT8IolS84skSs0vkqjoPL+ZFQF4EkAhAAcwyt3/ZGaNAUwA0A7AKgBXuvun7HPVqVMHbdu2DeYl\nJSV0LOwI79ie/y1atKB5+/btaX7BBRcEs6FDh9LaWbNm0Tw2N1tQUEDz5s2bB7PYcc+xOeWxY8fS\n/JVXXqH57t27g9no0fykd7bmHQBee+01mjdr1iyY/e53v6O17dq1o3lsH4zYeQjsePHYGRSsT2Jn\nPFRUmWf+MgC/cvdTAJwBYIiZnQLgNgBT3f1EAFMz74vIt0S0+d19vbvPzby9HcASAK0B9AcwLvNh\n4wBcdrgGKSI17xv9zm9m7QB0AzATQKG7f/Ez4yco/7VARL4lKt38ZtYAwHMAhrr7toqZl/8CdMhf\ngsxssJnNNrPZW7ZsqdZgRaTmVKr5zaw2yhv/GXd/PnPzBjNrmclbAjjkq1buPsrdi929uEmTJjUx\nZhGpAdHmNzMDMBrAEnf/Y4XoJQDXZt6+FsCLNT88ETlcKrOk90wA1wBYaGZfrMEcDuA+AM+a2c8A\nrAZwZewTbd26FRMnTgzmsa2ce/fuHcw++OADWhvbXnvr1q00v+qqq4LZ/v37aW3fvn1pvmTJEprH\nluXu2LEjmG3fvp3Wxh6XxYsX07xnz540P+qoo6r8uWNTnJddxl9jZtOQZ555Jq2NLRdes2YNzadN\nm0bzunXrBrPY9CybGmbblX9VtPnd/W0AoX3Az6n0PYlIXtEVfiKJUvOLJErNL5IoNb9IotT8IolS\n84skKqtbdxcWFtLlr7Etrq+44opgNmzYMFpbu3ZtmrO5coDPOcdqY9uGx5Ybx5Yrs2Wcr7/+Oq3t\n2rUrzWPHZMeWK3/44YfBLPa4rFy5kuaxZbX9+vULZrFl1MuXL6d5zL59+2jOtlvfuXMnrWXLgffu\n3UtrK9Izv0ii1PwiiVLziyRKzS+SKDW/SKLU/CKJUvOLJCqr8/wlJSW46aabgvmIESNoPTtyuVu3\nbrT2hRdeoPmQIUNoztbsx/YSiG0LHtvmOTZnXFgY3j5xzpw5tHbPnj00j83jH3fccTRv1apVMItd\nH7Fr1y6ax/ZgYHP5bCt2IL4PAluPD8T3KmDXKMRq2V4DTz/9NK2tSM/8IolS84skSs0vkig1v0ii\n1PwiiVLziyRKzS+SqKzO87do0QK33357MB85ciSt79WrVzBbsWIFrX300UdpXlpaSnO2/pqtGwfi\newmMHz+e5s8//zzN77nnnmDWpk0bWhs7Bjs2j1+vXj2av/zyy8GsS5cutPbUU0+l+dSpU2n+m9/8\nJpixo8MBYNu2bTSPXZvBvlcBgJ1e9d5779Fats9B7PqEivTML5IoNb9IotT8IolS84skSs0vkig1\nv0ii1PwiiYrO85tZEYAnARQCcACj3P1PZnYXgOsBbMp86HB3n8w+1+bNmzF69OhgXlJSQsfSvXv3\nYHbsscfS2nHjxtH88ssvpzlbJx27706dOtG8Vq1aNI/tb79hw4Zg1qFDB1p744030vyWW26heVFR\nEc179OgRzGLr1pctW0ZzNlcO8OsABgwYQGtj8/ixufiePXvSfOLEicGsQYMGtJbtJWBmtLaiylzk\nUwbgV+4+18wKAMwxsymZ7EF35ztwiEheija/u68HsD7z9nYzWwKg9eEemIgcXt/od34zawegG4CZ\nmZtuNLMFZjbGzBoFagab2Wwzmx3blklEsqfSzW9mDQA8B2Cou28D8AiADgC6ovwngwcOVefuo9y9\n2N2LY9eBi0j2VKr5zaw2yhv/GXd/HgDcfYO7H3D3gwAeAxB+NU5E8k60+a385cPRAJa4+x8r3N6y\nwoddDmBRzQ9PRA4Xix1zbGa9AbwFYCGAg5mbhwO4GuU/8juAVQBuyLw4GNSwYUNnUyDXXHMNHQvb\ninndunW09pxzzqF57DhoNr1y8ODBYAbEl49edtllNI8duzxjxoxgFptGjC3pZdtEA3z6FQCWLl0a\nzGLHYHfu3JnmsS3T27VrF8wWLeLPVc2bN6d57Ijv2JQb+5pv2bKF1rIty3/9619jxYoVlZrvq8yr\n/W8DONQno3P6IpLfdIWfSKLU/CKJUvOLJErNL5IoNb9IotT8IonK6tbdrVu3xr333hvMY3On7Jjs\ngoICWltWVkbz+vXr05zN28bmuh9++GGaz58/n+ZnnHEGzQcOHBjMqrssNnbf77zzDs0//vjjYBab\n548tu419v/z73/8OZrFls+w4eADo06cPzdkyawB46623gllsy/Li4uJg9k0uodczv0ii1PwiiVLz\niyRKzS+SKDW/SKLU/CKJUvOLJCq6nr9G78xsE4DVFW5qCmBz1gbwzeTr2PJ1XIDGVlU1Obbj3L1Z\nZT4wq83/tTs3m+3u4SsWcihfx5av4wI0tqrK1dj0Y79IotT8IonKdfOPyvH9M/k6tnwdF6CxVVVO\nxpbT3/lFJHdy/cwvIjmSk+Y3swvMbKmZrTCz23IxhhAzW2VmC81svpnNzvFYxpjZRjNbVOG2xmY2\nxcyWZ/4+5DFpORrbXWa2NvPYzTezi3I0tiIze93MPjSzxWZ2c+b2nD52ZFw5edyy/mO/mdUCsAxA\nPwClAN4HcLW7f5jVgQSY2SoAxe6e8zlhM+sDYAeAJ929U+a2/wKw1d3vy/zH2cjdb82Tsd0FYEeu\nT27OHCjTsuLJ0gAuA/AfyOFjR8Z1JXLwuOXimb87gBXuvtLd9wEYD6B/DsaR99z9TQBfPaGhP4Bx\nmbfHofybJ+sCY8sL7r7e3edm3t4O4IuTpXP62JFx5UQumr81gJIK75civ478dgCvmdkcMxuc68Ec\nQmGFk5E+AVCYy8EcQvTk5mz6ysnSefPYVeXE65qmF/y+rre7nw7gQgBDMj/e5iUv/50tn6ZrKnVy\nc7Yc4mTp/5fLx66qJ17XtFw0/1oARRXeb5O5LS+4+9rM3xsBTEL+nT684YtDUjN/843ssiifTm4+\n1MnSyIPHLp9OvM5F878P4EQzO97M6gC4CsBLORjH15hZ/cwLMTCz+gDOQ/6dPvwSgGszb18L4MUc\njuVL8uXk5tDJ0sjxY5d3J167e9b/ALgI5a/4fwzg9lyMITCu9gA+yPxZnOuxAfgbyn8M3I/y10Z+\nBqAJgKkAlgP4XwCN82hsT6H8NOcFKG+0ljkaW2+U/0i/AMD8zJ+Lcv3YkXHl5HHTFX4iidILfiKJ\nUvOLJErNL5IoNb9IotT8IolS84skSs0vkig1v0ii/g/+4bPkp4QfrwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1196bb048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    generated_image = sess.run(generated_image_output, feed_dict={z_placeholder: z_batch})\n",
    "    generated_image = generated_image.reshape([28,28])\n",
    "    plt.imshow(generated_image, cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "batch_size = 50\n",
    "\n",
    "z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions], name='z_placeholder')\n",
    "# feeding input noise to the generator\n",
    "\n",
    "x_placeholder = tf.placeholder(tf.float32, shape=[None, 28,28,1], name='x_placeholder')\n",
    "# feeding input images to the discriminator\n",
    "\n",
    "Gz = generator(z_placeholder, batch_size, z_dimensions)\n",
    "# hold generated images\n",
    "\n",
    "with tf.variable_scope(tf.get_variable_scope(), reuse=False) as scope:\n",
    "    Dx = discriminator(x_placeholder)\n",
    "# hold discriminator prediction probabilities for the **real MNIST** images\n",
    "\n",
    "with tf.variable_scope(tf.get_variable_scope(), reuse=True) as scope:\n",
    "    Dg = discriminator(Gz, reuse=True)\n",
    "# hold discriminator prediction probabilities for **generated** images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dx, labels=tf.ones_like(Dx)))\n",
    "d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.zeros_like(Dg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=Dg, labels=tf.ones_like(Dg)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['d_w1:0', 'd_b1:0', 'd_w2:0', 'd_b2:0', 'd_w3:0', 'd_b3:0', 'd_w4:0', 'd_b4:0']\n",
      "['g_w1:0', 'g_b1:0', 'g_w2:0', 'g_b2:0', 'g_w3:0', 'g_b3:0', 'g_w4:0', 'g_b4:0']\n"
     ]
    }
   ],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]\n",
    "\n",
    "print([v.name for v in d_vars])\n",
    "print([v.name for v in g_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(tf.get_variable_scope(), reuse=True) as scope:\n",
    "    # Train the discriminator\n",
    "    # fake, real\n",
    "    d_trainer_fake = tf.train.AdamOptimizer(0.0003).minimize(d_loss_fake, var_list=d_vars)\n",
    "    d_trainer_real = tf.train.AdamOptimizer(0.0003).minimize(d_loss_real, var_list=d_vars)\n",
    "\n",
    "    # Train the generator\n",
    "    g_trainer = tf.train.AdamOptimizer(0.0001).minimize(g_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(tf.get_variable_scope(), reuse=True) as scope:\n",
    "    tf.summary.scalar('Generator_loss', g_loss)\n",
    "    tf.summary.scalar('Discriminator_loss_real', d_loss_real)\n",
    "    tf.summary.scalar('Discriminator_loss_fake', d_loss_fake)\n",
    "\n",
    "    images_for_tensorboard = generator(z_placeholder, batch_size, z_dimensions)\n",
    "    tf.summary.image('Generated_images', images_for_tensorboard, 5)\n",
    "    merged = tf.summary.merge_all()\n",
    "    logdir = \"tensorboard/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "    writer = tf.summary.FileWriter(logdir, sess.graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dLossReal:  0.693681 dLossFake:  0.708278\n",
      "dLossReal:  0.0176743 dLossFake:  0.0365436\n",
      "dLossReal:  0.000669204 dLossFake:  0.00093111\n",
      "Iteration:  0 at 2017-08-31 22:00:02.778646\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'reshape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-55a2b4fb47fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mgenerated_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_placeholder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dimensions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mz_placeholder\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mz_batch\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Greys'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reshape' is not defined"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "with tf.variable_scope(tf.get_variable_scope(), reuse=True) as scope:\n",
    "    # Pre-train discriminator\n",
    "    for i in range(300):\n",
    "        z_batch = np.random.normal(0,1,size=[batch_size, z_dimensions])\n",
    "        real_image_batch = mnist.train.next_batch(batch_size)[0].reshape([batch_size, 28,28,1])\n",
    "        _, _, dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake], {x_placeholder: real_image_batch, z_placeholder: z_batch})\n",
    "\n",
    "        if i%100 == 0:\n",
    "            print(\"dLossReal: \", dLossReal, \"dLossFake: \", dLossFake)\n",
    "\n",
    "    # Train generator and discriminator together\n",
    "    # for i in range(100000):\n",
    "    for i in range(1000):\n",
    "        real_image_batch = mnist.train.next_batch(batch_size)[0].reshape([batch_size, 28,28,1])\n",
    "        z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "\n",
    "        # Train discriminator on both real and fake images\n",
    "        _, _, dLossReal, dLossFake = sess.run([d_trainer_real, d_trainer_fake, d_loss_real, d_loss_fake], {x_placeholder: real_image_batch, z_placeholder: z_batch})\n",
    "\n",
    "        # Train generator\n",
    "        z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "        _ = sess.run(g_trainer, feed_dict={z_placeholder: z_batch})\n",
    "\n",
    "        if i%10 == 0:\n",
    "            # Update TensorBoard with summary statistics\n",
    "            z_batch = np.random.normal(0,1,size=[batch_size, z_dimensions])\n",
    "            summary = sess.run(merged, {z_placeholder: z_batch, x_placeholder: real_image_batch})\n",
    "            writer.add_summary(summary, i)\n",
    "\n",
    "        if i% 100 == 0:\n",
    "            # Every 100 iterations, show a generated image\n",
    "            print('Iteration: ', i, 'at', datetime.datetime.now())\n",
    "            z_batch = np.random.normal(0,1,size=[1, z_dimensions])\n",
    "            generated_images = generator(z_placeholder, 1, z_dimensions)\n",
    "            images = sess.run(generated_images, {z_placeholder: z_batch})\n",
    "            plt.imshow(images[0].reshape([28,28]), cmap='Greys')\n",
    "            plt.show()\n",
    "\n",
    "            # Show discriminator's estimate\n",
    "            im = images[0].reshape([1,28,28, 1])\n",
    "            result = discriminator(x_placeholder)\n",
    "            estimate = sess.run(result, {x_placeholder: im})\n",
    "            print(\"Estimate: \", estimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
